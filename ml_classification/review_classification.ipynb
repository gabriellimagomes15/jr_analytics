{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICADOR DE REVIEWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DADOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://www.shanelynn.ie/select-pandas-dataframe-rows-and-columns-using-iloc-loc-and-ix/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import random\n",
    "from random import shuffle\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##carregando dados, filtrando-os e salvando e um novo objeto\n",
    "\n",
    "dados = pd.read_csv('data/reviewFinal.csv',encoding='latin-1')\n",
    "corpus = pd.DataFrame()\n",
    "listTitle = []\n",
    "listRecom = []\n",
    "prediTitle = []\n",
    "\n",
    "for i, r in dados.iterrows():\n",
    "    if r['recommend'] != 'NI' and r['title'] != \"\" and r['title'] is not np.nan: # and r['site'] == \"glassdoor\":\n",
    "        listTitle.append(r['title'])\n",
    "        listRecom.append(r['recommend'])\n",
    "    elif r['recommend'] == 'NI' and r['title'] is not np.nan:\n",
    "        prediTitle.append(r['title'])\n",
    "\n",
    "## criando objeto para encoder\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus['title']     = listTitle\n",
    "corpus['recommend'] = listRecom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GERANDO LINHAS PARA DADOS DE TREINO E TESTE\n",
    "x = [ i for i in range(len(corpus))]\n",
    "shuffle(x)\n",
    "\n",
    "rows_train =  x[0:round( len(corpus) * .80)] #25000\n",
    "rows_test  = x[round( len(corpus) * .80):(len(corpus))]\n",
    "dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### LIMPANDO TEXTO\n",
    "stemmerEng  = SnowballStemmer(\"english\")\n",
    "stemmerPort = SnowballStemmer(\"portuguese\")\n",
    "\n",
    "sClear = []\n",
    "tr = str.maketrans(\"\", \"\", string.punctuation)\n",
    "i = 0\n",
    "for i,text in corpus.iterrows():    \n",
    "    #print(text['title'].split())\n",
    "    clear = \"\"\n",
    "    for word in text['title'].split():        \n",
    "        word = word.lower() ## CONVERTENDO PARA MINUSCULO\n",
    "        word = word.translate(tr) ##REMOVENDO PONTUAÇÕES        \n",
    "        word = re.sub(\"\\d\",\" \",word) ## REMOVENDO NUMEROS\n",
    "        word = stemmerEng.stem(word) ## STEMM\n",
    "        word = stemmerPort.stem(word) ## STEMM\n",
    "        \n",
    "        clear = clear + ' ' + word\n",
    "        clear = re.sub(\"\\s+\",\" \",clear) ## REMOVENDO ESPAÇOS DUPLICADOS\n",
    "        clear = clear.strip()\n",
    "\n",
    "        \n",
    "    sClear.append(clear)\n",
    "    text['title'] = clear\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediTitleClean = []\n",
    "for title in prediTitle:\n",
    "    clear = \"\"\n",
    "    for word in title.split():        \n",
    "        word = word.lower() ## CONVERTENDO PARA MINUSCULO\n",
    "        word = word.translate(tr) ##REMOVENDO PONTUAÇÕES        \n",
    "        word = re.sub(\"\\d\",\" \",word) ## REMOVENDO NUMEROS\n",
    "        word = stemmerEng.stem(word) ## STEMM\n",
    "        word = stemmerPort.stem(word) ## STEMM\n",
    "        \n",
    "        clear = clear + ' ' + word\n",
    "        clear = re.sub(\"\\s+\",\" \",clear) ## REMOVENDO ESPAÇOS DUPLICADOS\n",
    "        clear = clear.strip()\n",
    "        \n",
    "    prediTitleClean.append(clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1} {0, 1}\n"
     ]
    }
   ],
   "source": [
    "train   = corpus.iloc[rows_train, [0]]\n",
    "train   = train['title'].tolist()\n",
    "train_y = corpus.iloc[rows_train, 1 ] \n",
    "train_y = encoder.fit_transform(train_y)\n",
    "\n",
    "test   = corpus.iloc[rows_test, [0]]\n",
    "test   = test['title'].tolist()\n",
    "test_y = corpus.iloc[rows_test, 1]\n",
    "test_y = encoder.fit_transform(test_y)\n",
    "\n",
    "print(set(train_y), set(test_y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ..., 1 1 1]\n",
      "      recommend\n",
      "46789       Yes\n",
      "28898       Yes\n",
      "61256       Yes\n",
      "37821       Yes\n",
      "7345        Yes\n",
      "28375        No\n",
      "84198       Yes\n",
      "42928       Yes\n",
      "55422       Yes\n",
      "22033        No\n",
      "2696         No\n",
      "74120        No\n",
      "62215       Yes\n",
      "85255       Yes\n",
      "3253         No\n",
      "44708        No\n",
      "69384       Yes\n",
      "70937       Yes\n",
      "7468        Yes\n",
      "62814       Yes\n",
      "72456       Yes\n",
      "39490       Yes\n",
      "62435       Yes\n",
      "81926        No\n",
      "13182        No\n",
      "11189        No\n",
      "22850       Yes\n",
      "82751        No\n",
      "3711        Yes\n",
      "59279       Yes\n",
      "...         ...\n",
      "42320        No\n",
      "80890       Yes\n",
      "3264        Yes\n",
      "12994       Yes\n",
      "9080        Yes\n",
      "38983        No\n",
      "54759        No\n",
      "38233        No\n",
      "27723       Yes\n",
      "29867       Yes\n",
      "10008        No\n",
      "45771       Yes\n",
      "13471       Yes\n",
      "83411       Yes\n",
      "67625       Yes\n",
      "30575        No\n",
      "22091       Yes\n",
      "46422        No\n",
      "4427        Yes\n",
      "58270       Yes\n",
      "58315       Yes\n",
      "11184       Yes\n",
      "56693       Yes\n",
      "11543       Yes\n",
      "25194       Yes\n",
      "64445       Yes\n",
      "74510       Yes\n",
      "136         Yes\n",
      "82677       Yes\n",
      "11065       Yes\n",
      "\n",
      "[68870 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_y)\n",
    "print(corpus.iloc[rows_train, [1] ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELOS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES MULTINOMIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68870, 8731)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#criando countVectorizer\n",
    "stopWords = stopwords.words('english') ##STOP WORD ENGLHIS\n",
    "[stopWords.append(w) for w in stopwords.words('portuguese')] ##STOP WORD PORTUGUES\n",
    "\n",
    "##STOP WORD NOME DAS EMPRESAS\n",
    "nameCompany = dados.company\n",
    "#[stopWords.append(i) for i in set(nameCompany)]\n",
    "\n",
    "count_vect     = CountVectorizer(stop_words = stopWords)\n",
    "X_train_counts = count_vect.fit_transform(train)\n",
    "count_vect.vocabulary_.get(u'algorithm')\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68870, 8731)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# criando TF-IDM\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf     = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CRIANDO OBJETO NAIVE BAYES E TREINANDO O MODELO\n",
    "clf = MultinomialNB().fit(X_train_tfidf, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FAZENDO TRANSFORMAÇÃO NOS DADOS DE TESTE E TESTANDO O MODELO NB\n",
    "X_new_counts = count_vect.transform(test)\n",
    "X_new_tfidf  = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2322  3399]\n",
      " [  650 10846]]\n",
      "\n",
      " acuracia :  0.764825463205\n"
     ]
    }
   ],
   "source": [
    "## Verificando acuracia do modelo\n",
    "print( confusion_matrix(test_y, predicted) ) \n",
    "print( '\\n acuracia : ', accuracy_score(test_y, predicted) )\n",
    "\n",
    "# acuracia :  \n",
    "# 0.7615191287349903\n",
    "# 0.763141081489\n",
    "# 0.764825463205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### salvando modelo\n",
    "import pickle\n",
    "f = open('NBMult.pickle', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classificando comentários sem recomendações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_predict_counts = count_vect.transform(prediTitleClean)\n",
    "X_predict_tfidf  = tfidf_transformer.transform(X_predict_counts)\n",
    "\n",
    "recom_predicted = clf.predict(X_predict_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Label (yes ou no) dos valores previstos\n",
    "#np.unique(recom_predicted,return_counts=True)\n",
    "\n",
    "labelPred = [ 'Yes' if rec == 1 else 'No' for rec in recom_predicted ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### salvando previsoes de recomendações\n",
    "pd.DataFrame({'predRecom': labelPred,'title': prediTitle}).to_csv('data/recommendPred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BINOMIAL NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(X_train_tfidf, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictBIN = nb.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2322  3399]\n",
      " [  650 10846]]\n",
      "\n",
      " acuracia :  0.760236975083\n"
     ]
    }
   ],
   "source": [
    "print( confusion_matrix(test_y, predicted) ) \n",
    "print( '\\n acuracia : ', accuracy_score(test_y, predictBIN) )\n",
    "#  acuracia :  \n",
    "# 0.760236975083\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Criando modelo SVC com Pipeline\n",
    "modeloSVC  = Pipeline([('vect', TfidfVectorizer(stop_words=stopwords.words('english'))), \n",
    "                    ('clf', SVC(kernel = 'linear', probability = True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "  ...',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#treinando modelo\n",
    "modeloSVC.fit(train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictSVC = modeloSVC.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print( confusion_matrix(test_y, predictSVC) ) \n",
    "print( '\\n acuracia : ', accuracy_score(test_y, predictSVC) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modeloSVM = Pipeline([('vect', CountVectorizer(stopwords.words('english'))),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, random_state=42,\n",
    "                                           max_iter=500, tol=None)),\n",
    "])\n",
    "modeloSVM.fit(train, train_y)  \n",
    "\n",
    "predicted = modeloSVM.predict(test)\n",
    "print( confusion_matrix(test_y, predicted) ) \n",
    "print( '\\n acuracia : ', accuracy_score(test_y, predicted) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIM!!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
